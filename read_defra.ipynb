{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "read_defra.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCXPpCvfhMjXcFJzTdiUUn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flowonthegoliv/ENVS666/blob/main/read_defra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6E8_YrQhyr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca4b21d-2c33-43d0-8894-d5c649693603"
      },
      "source": [
        "filename = 'data/defra/NO2_2020.csv' # here we can read in the DEFRA data\n",
        "# this reads in the data and tidies it up. Don't worry if you don't understand it! \n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "url = f'https://raw.githubusercontent.com/flowonthegoliv/ENVS666/main/{filename}'\n",
        "df = pd.read_csv(url, skiprows=0,dtype='unicode')\n",
        "df = df.drop(df.columns[range(3,df.shape[1],2)],axis=1)\n",
        "df = df.drop([0,df.shape[0]-1],axis=0)\n",
        "df = df.rename({df.columns[0]: 'Date & Time'},axis=1)\n",
        "# df = df[df.columns[range(1,df.shape[1])]].apply(pd.to_numeric)\n",
        "df = df.replace(['No data'],'9999')\n",
        "\n",
        "# df['Date & Time']\n",
        "# # for i in range (0,np.size(df,0)):\n",
        "# year = np.int(df['Date & Time'][i][0:4])\n",
        "# month = np.int(df['Date & Time'][i][5:7])\n",
        "# day = np.int(df['Date & Time'][i][8:10])\n",
        "# hour = np.int(df['Date & Time'][i][11:13]);\n",
        "# min = np.int(df['Date & Time'][i][14:16]);\n",
        "# if hour == 24: \n",
        "#   hour =0;\n",
        "# d = datetime.datetime(year, month, day, hour, min)\n",
        "# df['Date & Time'][i]=d\n",
        "for i in range(1,df.shape[1]):\n",
        "  df.iloc[:, [i]] = df.iloc[:, [i]].apply(pd.to_numeric)\n",
        "df[df.columns[0]] = pd.to_datetime(df[df.columns[0]]);\n",
        "df = df.replace([9999],np.nan)\n",
        "# this finished the complex bit - again don't worry I am just tidying \n",
        "print(df)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Date & Time  Aberdeen  ...  BirminghamLadywood    Average\n",
            "1    2020-01-01 02:00:00  16.12638  ...            38.64268  25.842617\n",
            "2    2020-01-01 03:00:00  14.06149  ...            29.32183  24.351879\n",
            "3    2020-01-01 04:00:00   8.35512  ...            31.50227  23.033982\n",
            "4    2020-01-01 05:00:00  11.05831  ...            35.75565  22.467340\n",
            "5    2020-01-01 06:00:00   5.45461  ...            24.33586  21.549001\n",
            "...                  ...       ...  ...                 ...        ...\n",
            "8777 2020-12-31 18:00:00  10.12974  ...            58.84205  43.545515\n",
            "8778 2020-12-31 19:00:00   5.47323  ...            67.79656  42.195239\n",
            "8779 2020-12-31 20:00:00   4.96291  ...            66.07638  38.471003\n",
            "8780 2020-12-31 21:00:00   4.60045  ...            59.12971  34.936681\n",
            "8781 2020-12-31 22:00:00   3.88380  ...            57.60769  31.915349\n",
            "\n",
            "[8781 rows x 84 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}